{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom os import makedirs\nfrom os.path import join, exists, expanduser\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.applications.imagenet_utils import decode_predictions\n\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)\n!ls ~/.keras/models  \n!cp ../input/keras-pretrained-models/*notop* ~/.keras/models/\n!cp ../input/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/\n!cp ../input/keras-pretrained-models/resnet50* ~/.keras/models/\n\n\n\n    \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\nall_xray_df = pd.read_csv('../input/data/Data_Entry_2017.csv')\nall_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input','data',  'images*', '*', '*.png'))}\nprint('Scans found:', len(all_image_paths), ', Total Headers:', all_xray_df.shape[0])\nall_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\nall_xray_df.sample(3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"100867dc3305a4595de35ce778984a6d602c140f"},"cell_type":"code","source":"#Here we take the labels and make them into a more clear format. The primary step is to see the distribution of findings and then to convert them to simple binary labels.\nlabel_counts = all_xray_df['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8084e54181811188106ac32bd79576db823956b"},"cell_type":"code","source":"#Removing No Finding images\nall_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\nfrom itertools import chain\nall_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\nall_xray_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89504ed7a0b470621807fed62c97b967586d081a"},"cell_type":"code","source":"print('All Labels ({})'.format(len(all_labels)), \n      [(c_label,int(all_xray_df[c_label].sum())) for c_label in all_labels])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c83074d070e1c6e16d91b3e26123771830556595"},"cell_type":"code","source":"# since the dataset is very unbiased, we can resample it to be a more reasonable collection\n# weight is 0.1 + number of findings\nsample_weights = all_xray_df['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\nsample_weights /= sample_weights.sum()\nall_xray_df = all_xray_df.sample(40000, weights=sample_weights)\n\nlabel_counts = all_xray_df['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07fe2bc46361f658bbd8b472acacc14427cb7fee"},"cell_type":"code","source":"label_counts = 100*np.mean(all_xray_df[all_labels].values,0)\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\nax1.set_xticklabels(all_labels, rotation = 90)\nax1.set_title('Adjusted Frequency of Diseases in Patient Group')\n_ = ax1.set_ylabel('Frequency (%)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84d38b1f42d47cfd34207e1c105c29d56deb5e0b"},"cell_type":"code","source":"#Preparing training and test data\nall_xray_df['disease_vec'] = all_xray_df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0d868346c3eeb9a222fe7759b2184b6c08a65f3"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(all_xray_df, \n                                   test_size = 0.25, \n                                   random_state = 2018,\n                                   stratify = all_xray_df['Finding Labels'].map(lambda x: x[:4]))\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])\nprint(all_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b453e0076b6efc384a121407b5e8d99bf691b732"},"cell_type":"code","source":"#Create Data Generators\nfrom keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (128,128)\ncore_idg = ImageDataGenerator(samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.05, \n                              width_shift_range=0.1, \n                              rotation_range=5, \n                              shear_range = 0.1,\n                              fill_mode = 'reflect',\n                              zoom_range=0.15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0d55d0fc36355853d0256972cab4bf36937d2a6"},"cell_type":"code","source":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91ed4cba35fbd299a8c114e39a97c5faf0d37d60"},"cell_type":"code","source":"train_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 32)\n\nvalid_gen = flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 256) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 1024)) # one big batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2eac9424d13a59289621775d864ad2a26896caa8"},"cell_type":"code","source":"t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -1.5, vmax = 1.5)\n    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n                             if n_score>0.5]))\n    c_ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"019b9b69cb6e8e37a48f7a9df26a02e8e1dd5839"},"cell_type":"code","source":"#Create a simple Model\nfrom __future__ import print_function, division\nfrom builtins import range, input\n\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\n# from keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('xray_class')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=3)\ncallbacks_list = [checkpoint, early]\n\nclass_weights = {0: 1.0787931408725853,\n 1: 5.166320166320166,\n 2: 3.7298311444652907,\n 3: 6.675621222296844,\n 4: 1.4675919090506422,\n 5: 7.161383285302594,\n 6: 10.22633744855967,\n 7: 79.52,\n 8: 1.0,\n 9: 3.4694589877835953,\n 10: 3.202319587628866,\n 11: 9.1109074243813,\n 12: 38.23076923076923,\n 13: 5.6477272727272725}\n\n\nres = ResNet50(input_shape=t_x.shape[1:], weights='imagenet', include_top=False)\n# don't train existing weights\nfor layer in res.layers:\n  layer.trainable = False\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5be85f331e9eb58300f733893b6d52f3d39f5a5"},"cell_type":"code","source":"x = Flatten()(res.output)\n# x = Dense(1000, activation='relu')(x)\nprediction = Dense(len(all_labels), activation='softmax')(x)\n\n# create a model object\nmodel = Model(inputs=res.input, outputs=prediction)\nmodel.summary()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"459b1f6b852f74159a65ba5ccf35a5826faabd9f"},"cell_type":"code","source":"#compile the model\nmodel.compile(\n  loss='binary_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9749da3cbde739524bbd665e78cbc1d4e614785a"},"cell_type":"code","source":"#Train the model\nr = model.fit_generator(\n  train_gen,\n  validation_data=(test_X, test_Y),\n  epochs=1,\n  steps_per_epoch= 30000/32,\n  callbacks = callbacks_list,\n  validation_steps= 10000 / 256,\n  class_weight = class_weights\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b01a1c8485a87aaf23c8b18375fea4a6ab6fbc17"},"cell_type":"code","source":"for c_label, s_count in zip(all_labels, 100*np.mean(test_Y,0)):\n    print('%s: %2.2f%%' % (c_label, s_count))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9aeb9e00ea53297ca9e7e93616bb367878b55e65"},"cell_type":"code","source":"pred_Y = model.predict(test_X, batch_size = 32, verbose = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"433b182f230ecf88fbbd07401b09a2107000bf78"},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('barely_trained_net.png')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"900dc713dd895a3546e6a9e9849de776f5caa776"},"cell_type":"code","source":"sickest_idx = np.argsort(np.sum(test_Y, 1)<1)\nfig, m_axs = plt.subplots(4, 2, figsize = (16, 32))\nfor (idx, c_ax) in zip(sickest_idx, m_axs.flatten()):\n    c_ax.imshow(test_X[idx, :,:,0], cmap = 'bone')\n    stat_str = [n_class[:6] for n_class, n_score in zip(all_labels, \n                                                                  test_Y[idx]) \n                             if n_score>0.5]\n    pred_str = ['%s:%2.0f%%' % (n_class[:4], p_score*100)  for n_class, n_score, p_score in zip(all_labels, \n                                                                  test_Y[idx], pred_Y[idx]) \n                             if (n_score>0.5) or (p_score>0.5)]\n    c_ax.set_title('Dx: '+', '.join(stat_str)+'\\nPDx: '+', '.join(pred_str))\n    c_ax.axis('off')\nfig.savefig('trained_img_predictions.png')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}